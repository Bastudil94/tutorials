{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction to High-Performance Computing (HPC)","text":"<p>Author: Bryam Astudillo Website: www.bryamastudillo.com </p> <p>Welcome to this tutorial on getting started with High-Performance Computing (HPC) on a cluster! This guide is designed to help you connect the worlds of structural engineering and computer science, empowering you to perform powerful research activities. While it does not delve deeply into structural engineering or computer science concepts, it provides the foundational skills to leverage HPC resources in your research.</p>"},{"location":"#what-youll-learn","title":"What You'll Learn","text":"<p>This tutorial covers the following topics:</p> <ul> <li>Setting Up Your Environment: Learn how to configure your work environment on the cluster.</li> <li>File System Management: Understand how to connect to the cluster and mirror your file system.</li> <li>SLURM Job Arrays: Set up SLURM job arrays to run Python scripts in parallel using HPC resources.</li> <li>Job Monitoring: Use basic commands to check the status of your jobs.</li> <li>Version Control with Git: Learn essential Git commands for managing a GitHub repository.</li> <li>Job Profiling: Discover basic profiling commands to identify bottlenecks and improve job performance.</li> </ul> <p>Note: Throughout this tutorial, I will use my username <code>bastudil</code>. Make sure to replace it with your own username wherever applicable!</p>"},{"location":"docs/README_Git_Python_Linux/","title":"1. README: Git and Python Environment Management in Linux","text":"<p>This README serves as a quick-start guide for managing Git repositories and Python environments in Linux, including handling Git submodules, configuring branches, and ensuring an updated Git version.</p> <p>learn more here</p>"},{"location":"docs/README_Git_Python_Linux/#11-install-a-package-from-github-using-pip","title":"1.1. Install a package from Github Using <code>pip</code>","text":"<p>You can install Python packages directly from GitHub using <code>pip</code>. Below are the different methods to do so:</p> <pre><code>pip install git+https://github.com/&lt;username&gt;/&lt;repository&gt;.git\n\npip install git+https://github.com/&lt;username&gt;/&lt;repository&gt;.git@&lt;branch&gt;\n\npip install git+https://github.com/&lt;username&gt;/&lt;repository&gt;.git@&lt;tag&gt;\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#12-update-on-cluster","title":"1.2. Update on cluster","text":"<pre><code>git fetch\ngit rebase origin/main\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#13-github-setting-up-the-credentials","title":"1.3. Github setting up the credentials","text":"<ul> <li>To been able to clone github repo first create a key in your sherlock profile. Then add the key in your GitHub account. Make sure to follow all steps and test the connection. For more details, refer to the official documentation or GitHub guides.</li> </ul> <p>Remove credentials</p> <p><pre><code> git config --local credential.helper \"\"\n\n git push origin master\n</code></pre> - Install a package from github</p>"},{"location":"docs/README_Git_Python_Linux/#14-git-basics-managing-repositories","title":"1.4. Git Basics: Managing Repositories","text":""},{"location":"docs/README_Git_Python_Linux/#141-clone-a-repository","title":"1.4.1. Clone a Repository","text":"<pre><code>git clone &lt;repository-url&gt;\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#142-update-your-local-repository","title":"1.4.2. Update Your Local Repository","text":"<p>Pull changes from a remote repository and branch:</p> <pre><code>git pull &lt;remote&gt; &lt;name-of-branch&gt;\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#143-check-the-status-of-your-repository","title":"1.4.3. Check the Status of Your Repository","text":"<p>View the current state of your local repository:</p> <pre><code>git status\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#144-compare-changes","title":"1.4.4. Compare Changes","text":"<p>See the differences between your working directory and the staged area:</p> <pre><code>git diff\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#15-commit-changes","title":"1.5. Commit Changes","text":""},{"location":"docs/README_Git_Python_Linux/#151-stage-files-for-commit","title":"1.5.1. Stage Files for Commit","text":"<p>Stage specific files or entire folders:</p> <pre><code>git add &lt;file-name OR folder-name&gt;\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#152-make-a-commit","title":"1.5.2. Make a Commit","text":"<p>Commit the staged changes with a descriptive message:</p> <pre><code>git commit -m \"COMMENT TO DESCRIBE THE INTENTION OF THE COMMIT\"\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#153-commit-all-changes","title":"1.5.3. Commit All Changes","text":"<p>Automatically stage and commit all modified and deleted files:</p> <pre><code>git commit -a -m \"COMMENT TO DESCRIBE THE INTENTION OF THE COMMIT\"\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#16-work-with-branches","title":"1.6. Work with Branches","text":""},{"location":"docs/README_Git_Python_Linux/#161-create-and-switch-to-a-new-branch","title":"1.6.1. Create and Switch to a New Branch","text":"<pre><code>git checkout -b &lt;name-of-branch&gt;\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#162-switch-to-an-existing-branch","title":"1.6.2. Switch to an Existing Branch","text":"<pre><code>git checkout &lt;name-of-branch&gt;\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#17-push-changes-to-remote","title":"1.7. Push Changes to Remote","text":""},{"location":"docs/README_Git_Python_Linux/#171-push-to-a-branch","title":"1.7.1. Push to a Branch","text":"<p>Push the changes to a remote branch:</p> <pre><code>git push &lt;remote&gt; &lt;name-of-branch&gt;\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#172-set-upstream-and-push","title":"1.7.2. Set Upstream and Push","text":"<p>If the branch has no upstream set, use:</p> <pre><code>git push --set-upstream &lt;remote&gt; &lt;name-of-branch&gt;\n</code></pre> <p>You can also configure this to happen automatically by modifying the Git configuration:</p> <pre><code>git config --global push.autoSetupRemote true\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#18-list-remote-repositories","title":"1.8. List Remote Repositories","text":"<p>To list remote URLs:</p> <pre><code>git remote -v\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#19-working-with-submodules","title":"1.9. Working with Submodules","text":""},{"location":"docs/README_Git_Python_Linux/#191-add-a-submodule","title":"1.9.1. Add a Submodule","text":"<pre><code>git submodule add &lt;repository-url&gt;\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#192-initialize-and-update-submodules","title":"1.9.2. Initialize and Update Submodules","text":"<pre><code>git submodule update --init --recursive\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#110-ensure-an-updated-version-of-git","title":"1.10. Ensure an Updated Version of Git","text":"<p>If your system has an older version of Git, load the latest module:</p> <pre><code>module load system\nmodule load git\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#111-python-environment-management","title":"1.11. Python Environment Management","text":""},{"location":"docs/README_Git_Python_Linux/#1111-activate-a-python-virtual-environment","title":"1.11.1. Activate a Python Virtual Environment","text":"<p>Navigate to the project folder and activate your virtual environment:</p> <pre><code>cd mod/OpenSeesPy_analysis_bxac/\nsource ~/myproject_env/bin/activate\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#1112-load-a-specific-python-version","title":"1.11.2. Load a Specific Python Version","text":"<p>If required, load the desired Python module:</p> <pre><code>module load python/3.9\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#1113-check-available-python-modules","title":"1.11.3. Check Available Python Modules","text":"<p>List all available modules in the current Python environment:</p> <pre><code>help(\"modules\")\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#1114-deactivate-the-python-environment","title":"1.11.4. Deactivate the Python Environment","text":"<pre><code>deactivate\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#112-example-workflow","title":"1.12. Example Workflow","text":"<ol> <li>Clone the Repository:</li> </ol> <p><pre><code>git clone git@github.com:username/repository.git\ncd repository\n</code></pre> 2. Create a Branch and Make Changes:</p> <p><pre><code>git checkout -b new-feature\n</code></pre> 3. Stage and Commit Changes:</p> <p><pre><code>git add .\ngit commit -m \"Implemented new feature\"\n</code></pre> 4. Push the Branch:</p> <p><pre><code>git push --set-upstream origin new-feature\n</code></pre> 5. Work with Submodules:</p> <p><pre><code>git submodule add git@github.com:Bastudil94/FrameSpineFLC-model.git\ngit submodule update --init --recursive\n</code></pre> 6. Set Up Python Environment:</p> <p><pre><code>module load python/3.9\nsource ~/myproject_env/bin/activate\n</code></pre> 7. Deactivate When Done:</p> <pre><code>deactivate\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#113-troubleshooting","title":"1.13. Troubleshooting","text":""},{"location":"docs/README_Git_Python_Linux/#1131-error-no-upstream-branch","title":"1.13.1. Error: \"No Upstream Branch\"","text":"<p>To resolve, use:</p> <pre><code>git push --set-upstream origin &lt;branch-name&gt;\n</code></pre>"},{"location":"docs/README_Git_Python_Linux/#1132-git-not-recognized-or-outdated","title":"1.13.2. Git Not Recognized or Outdated","text":"<p>Ensure Git is updated by loading the module:</p> <pre><code>module load system\nmodule load git\n</code></pre> <p>This guide covers the essentials to manage Git repositories and Python environments efficiently in a Linux environment.</p>"},{"location":"docs/RunCluster_info/","title":"Working on the HPC cluster","text":""},{"location":"docs/RunCluster_info/#1-common-commands","title":"1. Common Commands","text":"<ul> <li>Connect to Sherlock:   <pre><code>ssh login.sherlock.stanford.edu\n</code></pre></li> <li>Enter a computing node:   <pre><code>sdev\n</code></pre></li> <li>Load Python:   <pre><code>module load python/3.9.0  # option 1\nml python/3.9.0           # option 2\n</code></pre></li> <li>Submit script:   <pre><code>bash submit.sh\n</code></pre></li> </ul>"},{"location":"docs/RunCluster_info/#2-other-commands","title":"2. Other Commands","text":"<ul> <li>Create a Python environment:   <pre><code> python3 -m venv myenv\n source myenv/bin/activate\n\n python3 --version # to check python version\n\n python3 runfile.py\n\n deactivate # to deactivate the environment\n</code></pre></li> </ul>"},{"location":"docs/RunCluster_info/#3-commands-needed-to-troubleshoot","title":"3. Commands Needed to Troubleshoot","text":"<ul> <li>Return Python version:</li> </ul> <p><pre><code>python --version\n</code></pre> - Check installed packages:</p> <p><pre><code>pip3 list\nconda info\n</code></pre> - Identify package location:</p> <p><pre><code>which pip\nwhich conda\nwhich python3\n</code></pre> - Go to an address</p> <pre><code>cd /d e:\\\n</code></pre> <ul> <li>Copy files</li> </ul> <pre><code>cp -av HPC ~/hpc-share/\n</code></pre> <ul> <li>Create a link path.</li> </ul> <pre><code>ln -s /nfs/hpc/share/astudilb hpc-share\n</code></pre> <ul> <li>Show what is in the path, including hidden elements:</li> </ul> <pre><code>ls -a hpc-share/\n</code></pre> <p>```</p>"},{"location":"docs/dailyuse/","title":"Daily use steps","text":"<p>Stanford Sherlock - Daily use steps</p>"},{"location":"docs/dailyuse/#1-get-started-for-the-day","title":"1. Get started for the day","text":"<ol> <li>Open the Windows Server Linux <code>WSL</code></li> <li>Clone your working folder</li> </ol> <p><pre><code>sshfs -o allow_other bastudil@login.sherlock.stanford.edu:./ ~/sherlock_home\n</code></pre> 3. Clone your scratch folder</p> <p><pre><code>sshfs -o allow_other bastudil@login.sherlock.stanford.edu:/scratch/users/bastudil/ ~/sherlock_scratch\n</code></pre> 4. Log into your account</p> <p><pre><code>ssh bastudil@login.sherlock.stanford.edu\n</code></pre> 5. Your now should be in a login node</p> <p>Use the login node to send sbatch commands (e.g., <code>sbash mybash.sh</code>) but not to run computing scripts (e.g., don't do <code>python run.py</code>)</p>"},{"location":"docs/dailyuse/#2-log-into-a-computing-node-and-run-your-app","title":"2. Log into a computing node and run your app","text":"<p>Now you are ready to submit your jobs. See a more detailed explanaiton on:</p> <ul> <li>Example 1. Run a python script in the cluster: here</li> <li>Example 2. Run a python script in parallel: here</li> </ul>"},{"location":"docs/initialsetup/","title":"1. Set up your environment","text":""},{"location":"docs/initialsetup/#11-enter-into-your-account-via-hss","title":"1.1. Enter into your account via hss","text":"<p>Open Windows Subsystem for Linux <code>WSL</code> and log into your account using your username.</p> <p>Note: Make sure to replace <code>bastudil</code> with your own <code>username</code></p> <pre><code>ssh bastudil@login.sherlock.stanford.edu\n</code></pre> <p>Log into a computing node. <pre><code>sdev\n</code></pre></p>"},{"location":"docs/initialsetup/#12-install-a-new-environment","title":"1.2. Install a New Environment","text":"<p>Use the following commands to create a new python environment.</p> <p>Load the module in the system. See more pre-installed software here <pre><code>module load python/3.9\n</code></pre></p> <p>Create the python environment <pre><code>python3 -m venv mypyenv\n</code></pre></p> <p>Activate the environment <pre><code># source /path/to/my/opensees/bin/activate\nsource \"/home/users/bastudil/mypyenv/bin/activate\"\n</code></pre></p> <p>Check python version <pre><code>python3 --version\n</code></pre></p> <p>Run an interactive python session. You will notice that the some python packages are not installed; you will need to install what you need. <pre><code>python3\n</code></pre></p> <p>Exit python <pre><code># you are in python\nexit()\n</code></pre></p> <p>Deactivate environment <pre><code>deactivate\n</code></pre></p> <p>Exit the computing node <pre><code>exit\n</code></pre></p>"},{"location":"docs/initialsetup/#13-install-packages-needed-to-run-opensees-and-tools","title":"1.3. Install Packages Needed to Run OpenSees and Tools","text":"<p>Go into your python environment and install the packages you need. <pre><code>python3 -m pip install --upgrade matplotlib pandas numpy\npython3 -m pip install --upgrade openseespy\n</code></pre></p> <p>You can see the version of the packages <pre><code># in the command line\npip show numpy\n</code></pre> or  <pre><code># in the python session\nimport numpy\nprint(numpy.__version__)\n</code></pre></p>"},{"location":"docs/initialsetup/#14-optional-avoiding-multiple-duo-prompts-when-you-log-using-wsl","title":"1.4. [optional] Avoiding multiple duo prompts when you log using <code>WSL</code>","text":"<p>You can set up your account to avoid multiple dup prompts; see more information here.</p> <p>Paste this in <code>\"\\\\wsl.localhost\\Ubuntu\\home\\bastudil_linux\\.ssh\\config\"</code></p> <pre><code>Host login.sherlock.stanford.edu\n    ControlMaster auto\n    ControlPath ~/.ssh/%l%r@%h:%p\n</code></pre>"},{"location":"docs/initialsetup/#15-commands-that-did-not-work-for-me","title":"1.5. Commands that did not work for me","text":"<p>If you encounter the following error, there was no need to update Conda or Anaconda:</p> <pre><code># Don't do this (wasn't needed)\nconda update conda\nconda update anaconda\n</code></pre> <p>Install a new environment. Using conda (Not working)</p> <p><code>Error: libstdc++.so.6: version `GLIBCXX_3.4.21' not found</code></p> <pre><code>module load anaconda\n#conda create -p /path/to/myenv conda pip setuptools\nconda create --name &lt;env_name&gt; python=3.8\nsource /path/to/my/opensees/bin/activate\nwhich python3\npython3 -m pip install openseespy\npython3 \n&gt;&gt;&gt; import openseespy.opensees as ops\n</code></pre> <p>Another option to install the virtual environment could be <pre><code>python3.9 -m venv mypy39\n</code></pre></p>"},{"location":"docs/other/","title":"Other","text":""},{"location":"docs/other/#1-file-system","title":"1. File system","text":"<p>Scratch has a system that is optimized for parallel (?)</p> <pre><code>lfs df\n\n\nlfs getstripe /scratch/users/bastudil/202411\n\n\nlfs setstripe -c 4 \"/scratch/users/bastudil/202411/Results\"\n</code></pre>"},{"location":"docs/other/#2-osu-cluster","title":"2. OSU cluster","text":"<ol> <li>Enter a submit node:</li> </ol> <p><pre><code>ssh astudilb@submit-a.hpc.engr.oregonstate.edu\n\ncd Windows.Documents/My\\ Documents/HPC\n</code></pre> 2. Enter a compute node:</p> <p><pre><code>srun --pty bash\n</code></pre> 3. Submit a bash script:</p> <p><pre><code>bash submit.sh\n</code></pre> 4. Check the status of computing nodes:</p> <p><pre><code>sql -u astudilb\n</code></pre> 5. Load modules for the OSU HPC</p> <p><pre><code>module load slur\n\nmmodule load anaconda\n\nmodule load python/3.9\n</code></pre> 6. Activate environment</p> <pre><code>source mypy39/bin/activate\n</code></pre>"},{"location":"docs/profiling/","title":"1. Profiling your job","text":"<p>There are a couple steps you can use to check the running time of your script and profile it for efficiency and more speed.</p>"},{"location":"docs/profiling/#11-single-script-using-linux-functionalities","title":"1.1. Single script. Using linux functionalities.","text":"<p>Get the time and memory resources at the end of the analysis.</p> <pre><code>/usr/bin/time -v python3 run.py\n</code></pre> <p>Result:</p> <pre><code>        Command being timed: \"python3 run.py\"\n        User time (seconds): 13.96\n        System time (seconds): 1.05\n        Percent of CPU this job got: 47%\n        Elapsed (wall clock) time (h:mm:ss or m:ss): 0:31.33\n        Average shared text size (kbytes): 0\n        Average unshared data size (kbytes): 0\n        Average stack size (kbytes): 0\n        Average total size (kbytes): 0\n        Maximum resident set size (kbytes): 206852\n        Average resident set size (kbytes): 0\n        Major (requiring I/O) page faults: 0\n        Minor (reclaiming a frame) page faults: 146494\n        Voluntary context switches: 9083\n        Involuntary context switches: 513\n        Swaps: 0\n        File system inputs: 96\n        File system outputs: 76096\n        Socket messages sent: 0\n        Socket messages received: 0\n        Signals delivered: 0\n        Page size (bytes): 4096\n        Exit status: 0\n</code></pre>"},{"location":"docs/profiling/#12-single-script-using-python-functionalities","title":"1.2. Single script. Using python functionalities.","text":"<p>More detailed profile of the time using <code>cProfile</code>, run:</p> <pre><code>python3 -m cProfile -o profile_output.prof run.py\n</code></pre> <p>This command creates a profile report in <code>profile_output.prof</code>, which you can view with:</p> <pre><code>python3 -m pstats profile_output.prof\n</code></pre> <p>Then, interactively:</p> <pre><code>sort cumtime\nstats 20\n</code></pre> <p>Or, to view a sorted profile output directly:</p> <pre><code>python3 -m cProfile -s time run.py\n</code></pre>"},{"location":"docs/profiling/#13-sbatch","title":"1.3. Sbatch","text":""},{"location":"docs/profiling/#131-original-command","title":"1.3.1. Original command","text":"<pre><code># Run the Python script with srun and pass the unique PID\nsrun --ntasks=1 --exclusive python3 run.py -myPID \"$pid\" &amp;\n</code></pre>"},{"location":"docs/profiling/#132-profiling-options-using-strace-preferred","title":"1.3.2. Profiling options using <code>strace</code> (preferred)","text":"<p>The following will output the action times but not the python functions that causes the action.</p> <pre><code>strace -o ./ignore/trace_${pid}_output.txt -T -tt -f srun --ntasks=1 --exclusive python3 run.py -myPID \"$pid\"\n</code></pre> <pre><code>strace -o ./ignore/trace_${pid}_output.txt -ff -tt -e trace=all python3 -m trace --trace run.py -myPID \"$pid\"\nstrace -o ./ignore/trace_${pid}_output.txt -T -tt -f -e trace=all srun --ntasks=1 --exclusive python3 -m trace --trace run.py -myPID \"$pid\"\n\ntrace_file=\"/scratch/users/bastudil/ignore/trace_${SLURM_ARRAY_TASK_ID}_${pid}.txt\"\nstrace -o $trace_file -T -tt -f -e trace=all srun --ntasks=1 --exclusive python3 -m trace --trace run.py -myPID \"$pid\" &amp;\n</code></pre> <pre><code># Define the output file for FDs\nFD_LOG_FILE=\"./ignore/fd_log_${SLURM_JOB_ID}.txt\"\n\n# Run your job in the background\nyour_program &amp;\n\n# Log all open FDs every few seconds\nwhile kill -0 $! 2&gt;/dev/null; do\n  echo \"Logging FDs at $(date)\" &gt;&gt; \"$FD_LOG_FILE\"\n  lsof -p $! &gt;&gt; \"$FD_LOG_FILE\"\n  sleep 5  # Log every 5 seconds, adjust as needed\ndone\n\n# Wait for the job to complete\nwait\n</code></pre> <pre><code>        perf record -F 99 -g -o $trace_data -- srun --ntasks=1 --exclusive python3 -m trace --trace run.py -myPID \"$pid\" &amp;\n\n\nperf report -i my_perf_data.data\n</code></pre> <p>.</p> <pre><code>strace -o $trace_file -T -tt -f -e trace=all srun --ntasks=1 --exclusive python3 -m cProfile -o $pstats run.py -myPID \"$pid\" &gt;&gt; \"$python_console\" 2&gt;&gt; \"$python_error\" &amp;\n\n\npython -m snakeviz \"\\\\wsl.localhost\\Ubuntu\\home\\bastudil_linux\\sherlock_scratch\\ignore\\55148051_80_profile.pstats\"\n</code></pre> <p>.</p> <pre><code>pip install pyinstrument\n\nstrace -o $trace_file -T -tt -f -e trace=all srun --ntasks=1 --exclusive pyinstrument -o $python_pyinstrument run.py -myPID \"$pid\" &gt;&gt; \"$python_console\" 2&gt;&gt; \"$python_error\" &amp;\n</code></pre> <p>If some module take long to import, you could preload the modules using <code>sitecustomize.py</code></p> <p>Using a sitecustomize.py file is a convenient way to preload modules in Python. This approach works well for reducing load times in HPC environments because the file is automatically executed by Python whenever the interpreter starts, making it suitable for preloading frequently used libraries across all scripts. Here\u2019s a detailed guide on setting up sitecustomize.py:</p> <p>import site print(site.getsitepackages())</p>"},{"location":"docs/profiling/#133-profiling-options-using-bintime","title":"1.3.3. Profiling options using <code>bin/time</code>","text":"<pre><code>/usr/bin/time -v  srun --ntasks=1 --exclusive python3 run.py -myPID \"$pid\" &amp; &gt; ./ignore/task_${pid}output.txt 2&gt; ./ignore/task${pid}_time.txt\n</code></pre>"},{"location":"docs/profiling/#134-profiling-options-using-perf","title":"1.3.4. Profiling options using <code>perf</code>","text":"<pre><code>perf stat -e 'cpu-clock,task-clock,context-switches,page-faults,cycles,instructions,cache-misses' srun --ntasks=1 --exclusive python3 run.py -myPID \"$pid\"\n</code></pre>"},{"location":"docs/useful_functionalities/","title":"Useful Commands","text":""},{"location":"docs/useful_functionalities/#1-functionalities","title":"1. Functionalities","text":""},{"location":"docs/useful_functionalities/#11-ask-for-a-computing-node","title":"1.1. Ask for a computing node","text":"<pre><code>sdev\nsh_dev -p serc\n</code></pre>"},{"location":"docs/useful_functionalities/#12-check-the-queue-of-your-jobs","title":"1.2. Check the queue of your jobs","text":"<pre><code>squeue -u bastudil\nwatch -n 2 squeue -u bastudil\n\nsqueue -p serc\nsqueue -p cee\n</code></pre> <pre><code>sacctmgr --acount=bastudil\ntop\n</code></pre>"},{"location":"docs/useful_functionalities/#13-cancel-your-jobs","title":"1.3. Cancel your jobs","text":"<pre><code>scancel -u bastudil\n</code></pre>"},{"location":"docs/useful_functionalities/#14-check-the-partitions-you-can-use","title":"1.4. Check the partitions you can use","text":"<pre><code>sh_part\n</code></pre>"},{"location":"docs/useful_functionalities/#15-check-your-team-usage","title":"1.5. Check your team usage","text":"<pre><code>squeue -A bsimpson -o \"%.18i %.9P %.8j %.8u %.2t %.C %.L\"\n\nsacctmgr -show qos format=Name,MaxTRESPerUser,MaxSubmitJobsPerUser,MaxJobsPerUser,MaxTresPerAccount, MaxSubmitJobsPerAccount,MaxJobsPerAccount,MaxWal\n</code></pre>"},{"location":"docs/useful_functionalities/#16-correct-your-sh-file","title":"1.6. Correct your .sh file.","text":"<p>Sometimes working in Windows and Linux will have formating issues.</p> <pre><code># sudo apt install dos2unix  # On Debian/Ubuntu-based systems\n# sudo yum install dos2unix  # On Red Hat-based systems\ndos2unix &lt;filename&gt;\n</code></pre>"},{"location":"docs/useful_functionalities/#2-other-tips","title":"2. Other tips","text":""},{"location":"docs/useful_functionalities/#21-other-modules-for-sherlock","title":"2.1. Other modules for Sherlock","text":"<pre><code>module load slurm\nmodule load anaconda\n</code></pre>"},{"location":"docs/wsl/","title":"Install Windows Subsystem for Linux (WSL)","text":""},{"location":"docs/wsl/#installing-wsl","title":"Installing WSL","text":"<p>If you are using Windows, I recommend you install WSL to interact with the cluster via HSS.</p> <p>Check more here</p>"},{"location":"docs/wsl/#other-options","title":"Other options","text":"<p>You could use MobaXterm</p>"},{"location":"docs/examples/new_2files/","title":"Example 3. Another sbatch example","text":""},{"location":"docs/examples/new_2files/#sbatch-file","title":"Sbatch file","text":"<p>This is the <code>run.sh</code>. <pre><code>#!/bin/bash\n\n#SBATCH --time=00:50:00\n#SBATCH --ntasks=10 # 10 tasks per job\n#SBATCH --cpus-per-task=1\n#SBATCH --mem=15000M # Total memory for the job (1500M * 10 tasks)\n#SBATCH --partition=serc\n#SBATCH --array=0-43 # Array from index 0 to 43, creating 44 jobs in total\n#SBATCH -o /scratch/users/bastudil/ignore/%j_%a_slurm.out # Separate STDOUT for each array task\n\n\n#----------------\n# Load any modules or environments with preinstalled requirements\nmodule load python/3.9.0\nsource \"/home/users/bastudil/myproject_env/bin/activate\"\n\n\n#----------------\n# Define the custom array of PIDs\n\n# myPID=(0 1 2 3 4 5 6 7 8 9 10)\n\nmyPID=()\nfor i in {0..2000}; do\n  myPID+=($i)  # Adds each number from 0 to 2000 into the array\ndone\n\n\n#----------------\n# Loop through each task manually to ensure each gets a unique PID\n\nfor task_id in $(seq 0 $((SLURM_NTASKS - 1))); do\n    # Calculate a unique index for each task within the array job\n    index=$((SLURM_ARRAY_TASK_ID * SLURM_NTASKS + task_id))\n\n    # Check to ensure index is within bounds of myPID array\n    if (( index &lt; ${#myPID[@]} )); then\n\n        #----------------\n        # Current pid\n        pid=${myPID[$index]}\n\n        #----------------\n        # Log detailed information about the job and task\n\n        now1=$(date +\"%T\")\n        echo \"Start time for job $SLURM_ARRAY_TASK_ID, task $task_id (manually assigned). PID $pid: $now1\"\n\n        #----------------\n        # filenames\n\n        python_console=\"/scratch/users/bastudil/ignore/${SLURM_JOB_ID}_${pid}_python_console.log\"\n        python_error=\"/scratch/users/bastudil/ignore/${SLURM_JOB_ID}_${pid}_python_error.log\"\n        python_pyinstrument=\"/scratch/users/bastudil/ignore/${SLURM_JOB_ID}_${pid}_python_pyinstrument.html\"\n\n        #----------------\n        # Run the Python script with srun and pass the unique PID\n\n        # srun --ntasks=1 --exclusive python3 run.py -myPID \"$pid\" &amp;\n        srun --ntasks=1 --exclusive run.py -myPID \"$pid\" &gt;&gt; \"$python_console\" 2&gt;&gt; \"$python_error\" &amp; # prints console to specific files\n        # srun --ntasks=1 --exclusive pyinstrument -o $python_pyinstrument run.py -myPID \"$pid\" &gt;&gt; \"$python_console\" 2&gt;&gt; \"$python_error\" &amp; # with profiling\n\n\n    fi\ndone\n\n\n\n\n# Wait for all background tasks to\u00a0complete\nwait\n</code></pre></p>"},{"location":"docs/examples/new_2files/#python-file","title":"Python file","text":"<p>This is the <code>run.py</code></p> <pre><code># You are in python now :)\n\nimport openseespy.opensees as ops\nimport os, sys\nimport time\nimport itertools\n\n\ndef yourcode():\n    # input arguments\n    Arg1 = sys.argv[1]\n    Arg2 = sys.argv[2]\n\n    # your python code here\n\n    # You are welcome\n\n\ndef main():\n    print(\"run.py started at: \",datetime.datetime.now())\n\n    yourcode()\n\n    print(\"run.py ended at: \",datetime.datetime.now())\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"docs/examples/previous_3files/","title":"1. A Quick Example","text":"<p>Three files are recommended to simplify the process.</p> <ul> <li>File 1: Do a list of the processes you need</li> <li>File 2: Intermediate file to pass the bash argument and start python (may not be needed if python3 is called directly from File 1.</li> <li>File 3: Your python code. Take advantage of the input arguments passed in the batch.</li> </ul> <p>See a template code below for each file.</p> <p>-File 1: <code>Submit.sh</code></p> <pre><code>  #!/bin/bash\n\n  module load python/3.9\n\n  source opensees/bin/activate\n\n\n  # JOBS\n\n  # srun would send individual jobs (Upto1000jobs?). Use 1 CPU each.\n\n\n  forSFin1.0; do\n\n      # sed \"s/FILENAME/$filename/\" template.sh &gt; $filename\\.sh\n\n      sbatch template.sh \"opt11\"$Model$gmID$SF;\n\n  done\n</code></pre> <p>-File 2: <code>template.sh</code></p> <pre><code>  #!/bin/bash\n\n\n  # Run job\n\n  # $@ refers to all the arguments\n\n\n  python3 RunFromCluster.py $@\n</code></pre> <p>-File 3: <code>RunFromCluster.py</code></p> <pre><code># You are in python now :)\n\nimport openseespy.opensees as ops\nimport os, sys\nimport time\nimport itertools\n\n# input arguments\nArg1 = sys.argv[1]\nArg2 = sys.argv[2]\n\n# your python code\n# You are welcome\n</code></pre>"},{"location":"docs/examples/simple/","title":"Example. Run a simple script.","text":""},{"location":"docs/examples/simple/#1-log-into-a-computing-node","title":"1. Log into a computing node","text":"<p>Request a compute node</p> <pre><code>sdev\n</code></pre>"},{"location":"docs/examples/simple/#load-the-modules-required-for-the-sherlock-environment","title":"Load the modules required for the Sherlock environment","text":"<pre><code>module load python/3.9.0\n</code></pre>"},{"location":"docs/examples/simple/#activate-your-python-environment","title":"Activate your python environment","text":"<p>Note: Replace the environment path <code>myproject_env</code></p> <pre><code># source &lt;environment&gt;/bin/activate\nsource \"/home/users/bastudil/myproject_env/bin/activate\"\n</code></pre>"},{"location":"docs/examples/simple/#run-your-python-script","title":"Run your python script","text":"<pre><code># python3 myfile.py             # call with no arguments\npython3 myfile.py -myPID 2      # call with arguments\n</code></pre>"},{"location":"docs/examples/simple/#complete-code","title":"Complete code","text":"<pre><code>sdev                                                        # ask for a compute node\nmodule load python/3.9.0                                    # load python\nsource \"/home/users/bastudil/myproject_env/bin/activate\"    # load the environment\npython3 myfile.py -myPID 2                                  # call python with arguments\n</code></pre>"},{"location":"docs/examples/simple_sbatch/","title":"Example 2. Run a python script using sbatch","text":""},{"location":"docs/examples/simple_sbatch/#sbatch-file","title":"Sbatch file","text":"<p>This is the <code>run.sh</code>. <pre><code>#!/bin/bash\n\n#SBATCH --time=00:04:00\n#SBATCH --ntasks=2 # 2 tasks per job\n#SBATCH --cpus-per-task=1\n#SBATCH --mem=3000M # Total memory for the job (1500M * 2 tasks)\n#SBATCH --partition=serc\n#SBATCH --array=0-4 # Array from index 0 to 4, creating 5 jobs in total\n#SBATCH -o /scratch/users/bastudil/ignore/%j_%a_slurm.out # Separate STDOUT for each array task\n\n\n#----------------\n# Load any modules or environments with preinstalled requirements\nmodule load python/3.9.0\nsource \"/home/users/bastudil/myproject_env/bin/activate\"\n\n\n#----------------\n# Define the custom array of PIDs\n\nmyPID=(0 1 2 3 4 5 6 7 8 9 10)\n\n\n#----------------\n# Loop through each task manually to ensure each gets a unique PID\n\nfor task_id in $(seq 0 $((SLURM_NTASKS - 1))); do\n    # Calculate a unique index for each task within the array job\n    index=$((SLURM_ARRAY_TASK_ID * SLURM_NTASKS + task_id))\n\n    # Check to ensure index is within bounds of myPID array\n    if (( index &lt; ${#myPID[@]} )); then\n\n        #----------------\n        # Current pid\n        pid=${myPID[$index]}\n\n        #----------------\n        # Run the Python script with srun and pass the unique PID\n        srun --ntasks=1 --exclusive python3 run.py -myPID \"$pid\" &amp;\n\n\n    fi\ndone\n\n\n\n\n# Wait for all background tasks to\u00a0complete\nwait\n</code></pre></p>"},{"location":"docs/examples/simple_sbatch/#python-file","title":"Python file","text":"<p>This is the <code>run.py</code></p> <pre><code># You are in python now :)\n\nimport openseespy.opensees as ops\nimport os, sys\nimport time\nimport itertools\n\n\ndef yourcode():\n    # input arguments\n    Arg1 = sys.argv[1]\n    Arg2 = sys.argv[2]\n\n    # your python code here\n\n    # You are welcome\n\n\ndef main():\n    print(\"run.py started at: \",datetime.datetime.now())\n\n    yourcode()\n\n    print(\"run.py ended at: \",datetime.datetime.now())\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"}]}